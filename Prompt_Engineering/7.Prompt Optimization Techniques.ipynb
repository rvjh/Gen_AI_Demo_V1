{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt Optimization Techniques\n",
    "\n",
    "As AI language models become more sophisticated, the quality of prompts used to interact with them becomes increasingly important. Optimized prompts can lead to more accurate, relevant, and useful responses, enhancing the overall performance of AI applications. This tutorial aims to equip learners with practical techniques to systematically improve their prompts.\n",
    "\n",
    "Key Components\n",
    "\n",
    "1. A/B Testing Prompts: A method to compare the effectiveness of different prompt variations.\n",
    "2. Iterative Refinement: A strategy for gradually improving prompts based on feedback and results.\n",
    "3. Performance Metrics: Ways to measure and compare the quality of responses from different prompts.\n",
    "4. Practical Implementation: Hands-on examples using OpenAI's GPT model and LangChain.\n",
    "Method Details\n",
    "\n",
    "A/B Testing:\n",
    "\n",
    "* Define multiple versions of a prompt\n",
    "* Generate responses for each version\n",
    "* Compare results using predefined metrics\n",
    "\n",
    "Iterative Refinement:\n",
    "\n",
    "* Start with an initial prompt\n",
    "* Generate responses and evaluate\n",
    "* Identify areas for improvement\n",
    "* Refine the prompt based on insights\n",
    "* Repeat the process to continuously enhance the prompt\n",
    "\n",
    "Performance Evaluation:\n",
    "\n",
    "* Define relevant metrics (e.g., relevance, specificity, coherence)\n",
    "* Implement scoring functions\n",
    "* Compare scores across different prompt versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x7f3895006f20>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x7f3895007a90>, model_name='gemma-7b-it', groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "groq_api_key = \"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\"\n",
    "\n",
    "llm = ChatGroq(\n",
    "     groq_api_key = groq_api_key,\n",
    "     model = \"gemma-7b-it\"\n",
    ")\n",
    "\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a helper function to generate responses\n",
    "def generate_response(prompt):\n",
    "    \"\"\"Generate a response using the language model.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The input prompt.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated response.\n",
    "    \"\"\"\n",
    "    return llm.invoke(prompt).content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A/B Testing Prompts\n",
    "\n",
    "Let's start with A/B testing by comparing different prompt variations for a specific task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating response based on clarity...\n",
      "Evaluating response based on informativeness...\n",
      "Evaluating response based on engagement...\n",
      "Evaluating response based on clarity...\n",
      "Evaluating response based on informativeness...\n",
      "Evaluating response based on engagement...\n",
      "Prompt A score: 9.00\n",
      "Prompt B score: 8.00\n",
      "Winning prompt: A\n"
     ]
    }
   ],
   "source": [
    "# Define prompt variations\n",
    "prompt_a = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=\"Explain {topic} in simple terms.\"\n",
    ")\n",
    "\n",
    "prompt_b = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=\"Provide a beginner-friendly explanation of {topic}, including key concepts and an example.\"\n",
    ")\n",
    "\n",
    "# Updated function to evaluate response quality\n",
    "def evaluate_response(response, criteria):\n",
    "    \"\"\"Evaluate the quality of a response based on given criteria.\n",
    "\n",
    "    Args:\n",
    "        response (str): The generated response.\n",
    "        criteria (list): List of criteria to evaluate.\n",
    "\n",
    "    Returns:\n",
    "        float: The average score across all criteria.\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    for criterion in criteria:\n",
    "        print(f\"Evaluating response based on {criterion}...\")\n",
    "        prompt = f\"On a scale of 1-10, rate the following response on {criterion}. Start your response with the numeric score:\\n\\n{response}\"\n",
    "        response = generate_response(prompt)\n",
    "        # show 50 characters of the response\n",
    "        # Use regex to find the first number in the response\n",
    "        score_match = re.search(r'\\d+', response)\n",
    "        if score_match:\n",
    "            score = int(score_match.group())\n",
    "            scores.append(min(score, 10))  # Ensure score is not greater than 10\n",
    "        else:\n",
    "            print(f\"Warning: Could not extract numeric score for {criterion}. Using default score of 5.\")\n",
    "            scores.append(5)  # Default score if no number is found\n",
    "    return np.mean(scores)\n",
    "\n",
    "# Perform A/B test\n",
    "topic = \"machine learning\"\n",
    "response_a = generate_response(prompt_a.format(topic=topic))\n",
    "response_b = generate_response(prompt_b.format(topic=topic))\n",
    "\n",
    "criteria = [\"clarity\", \"informativeness\", \"engagement\"]\n",
    "score_a = evaluate_response(response_a, criteria)\n",
    "score_b = evaluate_response(response_b, criteria)\n",
    "\n",
    "print(f\"Prompt A score: {score_a:.2f}\")\n",
    "print(f\"Prompt B score: {score_b:.2f}\")\n",
    "print(f\"Winning prompt: {'A' if score_a > score_b else 'B'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterative Refinement\n",
    "\n",
    "Now, let's demonstrate the iterative refinement process for improving a prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating response based on clarity...\n",
      "Evaluating response based on informativeness...\n",
      "Evaluating response based on engagement...\n",
      "Evaluating response based on clarity...\n",
      "Evaluating response based on informativeness...\n",
      "Evaluating response based on engagement...\n",
      "Prompt A score: 9.00\n",
      "Prompt B score: 8.00\n",
      "Winning prompt: A\n",
      "Iteration 1 prompt: ## Explain Machine Learning in simple terms.\n",
      "\n",
      "**What is Machine Learning (ML)?**\n",
      "\n",
      "Imagine a computer that can learn and make predictions on its own. That's the power of Machine Learning (ML)! It's a branch of artificial intelligence where computers learn from data, identifying patterns and making future predictions or decisions without explicit programming. Think of it like teaching a computer to recognize patterns in things like images, text, or even human behavior.\n",
      "\n",
      "**How does ML learn?**\n",
      "\n",
      "ML algorithms are trained on labeled or unlabeled data. Like studying a bunch of pictures of cats and dogs, the algorithm learns to recognize the difference between the two. This process is called \"training.\" The more data you feed the algorithm, the better it becomes at making predictions.\n",
      "\n",
      "**Types of Machine Learning:**\n",
      "\n",
      "* **Supervised learning:** Teaches the computer labeled data, like showing it a cat picture and saying \"this is a cat.\" The algorithm learns to recognize cats in new images.\n",
      "* **Unsupervised learning:** Discovers hidden patterns in unlabeled data, like finding similarities between different songs in a playlist.\n",
      "* **Reinforcement learning:** Teaches the computer through rewards and punishments. For example, a robot learns to navigate an environment by receiving rewards for reaching a goal and punishments for hitting obstacles.\n",
      "\n",
      "**Real-world applications of ML:**\n",
      "\n",
      "ML has revolutionized various sectors:\n",
      "\n",
      "* **Healthcare:** Diagnosing diseases from medical images, predicting patient outcomes, and automating tasks like medication scheduling.\n",
      "* **Finance:** Fraud detection, credit risk assessment, and automated trading decisions.\n",
      "* **Transportation:** Autonomous vehicles, predictive traffic flow management, and personalized travel recommendations.\n",
      "* **Entertainment:** Content recommendation systems, image recognition for photo editing, and voice assistants like Siri and Alexa.\n",
      "\n",
      "**Key Concepts in ML:**\n",
      "\n",
      "Machine learning involves concepts like algorithms, data sets, accuracy, precision, recall, and loss functions. These terms describe how well the algorithm performs and how efficiently it can learn and make predictions.\n",
      "\n",
      "**Challenges and Considerations:**\n",
      "\n",
      "While ML offers significant potential, it also faces challenges. Data bias can lead to unfair algorithms, interpretability concerns make it difficult to understand how algorithms reach decisions, and privacy issues arise when dealing with sensitive data.\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "Machine Learning is a rapidly evolving field with diverse applications across industries. By leveraging its power responsibly, we can automate tasks, make better predictions, and revolutionize various aspects of our lives.\n",
      "Iteration 2 prompt: ## Improved Prompt Template:\n",
      "\n",
      "## Explain Machine Learning in simple terms.\n",
      "\n",
      "**What is Machine Learning (ML)?**\n",
      "\n",
      "Machine Learning (ML) is a branch of artificial intelligence where computers learn from data, identifying patterns and making predictions or decisions without explicit programming. It's like teaching a computer to recognize patterns in things like images, text, or even human behavior.\n",
      "\n",
      "**How does ML learn?**\n",
      "\n",
      "ML algorithms are trained on labeled or unlabeled data. The algorithm learns from the data, identifying patterns and making predictions for future instances. This process is called \"training.\"\n",
      "\n",
      "**Types of Machine Learning:**\n",
      "\n",
      "* **Supervised learning:** Teaches the computer labeled data, like showing it a cat picture and saying \"this is a cat.\"\n",
      "* **Unsupervised learning:** Discovers hidden patterns in unlabeled data, like finding similarities between different songs in a playlist.\n",
      "* **Reinforcement learning:** Teaches the computer through rewards and punishments. For example, a robot learns to navigate an environment by receiving rewards for reaching a goal and punishments for hitting obstacles.\n",
      "\n",
      "**Real-world applications of ML:**\n",
      "\n",
      "ML has revolutionized various sectors:\n",
      "\n",
      "* **Healthcare:** Diagnosing diseases from medical images, predicting patient outcomes, and automating tasks like medication scheduling.\n",
      "* **Finance:** Fraud detection, credit risk assessment, and automated trading decisions.\n",
      "* **Transportation:** Autonomous vehicles, predictive traffic flow management, and personalized travel recommendations.\n",
      "* **Entertainment:** Content recommendation systems, image recognition for photo editing, and voice assistants like Siri and Alexa.\n",
      "\n",
      "**Key Concepts in ML:**\n",
      "\n",
      "Machine learning involves concepts like algorithms, data sets, accuracy, precision, recall, and loss functions. These terms describe how well the algorithm performs and how efficiently it can learn and make predictions.\n",
      "\n",
      "**Challenges and Considerations:**\n",
      "\n",
      "While ML offers significant potential, it also faces challenges:\n",
      "\n",
      "* **Data bias:** ML algorithms can inherit or amplify biases present in the training data.\n",
      "* **Interpretability:** Understanding how ML models arrive at their predictions can be difficult.\n",
      "* **Privacy concerns:** Handling and securing sensitive data raises ethical and legal concerns.\n",
      "* **Job displacement:** Automation using ML may potentially displace certain jobs.\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "Machine Learning is a powerful technology with diverse applications across industries. By leveraging its power responsibly and addressing its challenges, we can automate tasks, make better predictions, and revolutionize various aspects of our lives.\n",
      "Iteration 3 prompt: ## Feedback on Improved Prompt Template:\n",
      "\n",
      "**Strengths:**\n",
      "\n",
      "* Clear and concise explanation of Machine Learning concepts.\n",
      "* Inclusion of different learning paradigms.\n",
      "* Comprehensive list of real-world applications.\n",
      "* Discussion of key concepts like algorithms, data sets, and ethical considerations.\n",
      "* Balanced tone that acknowledges both the potential and limitations of ML.\n",
      "\n",
      "**Suggestions for improvement:**\n",
      "\n",
      "* **Add a section on the future of ML:** Discuss potential future applications, challenges, and ethical considerations.\n",
      "* **Provide more specific examples:** Include concrete examples of how ML is used in each application mentioned.\n",
      "* **Visualize complex concepts:** Consider using diagrams or illustrations to explain algorithms, data flow, and model performance.\n",
      "* **Simplify explanations for non-technical audiences:** Use analogies or relatable metaphors to explain technical terms.\n",
      "* **Consider the impact of ML on society:** Discuss potential job displacement and social implications.\n",
      "\n",
      "**Additional recommendations:**\n",
      "\n",
      "* Briefly explain different types of ML algorithms (e.g., linear regression, logistic regression, decision trees, k-nearest neighbors).\n",
      "* Include a section on applications of ML in specific industries like healthcare, finance, and education.\n",
      "* Discuss the importance of data quality and feature engineering in ML model performance.\n",
      "\n",
      "Final refined prompt:\n",
      "## Feedback on Improved Prompt Template:\n",
      "\n",
      "**Strengths:**\n",
      "\n",
      "* Clear and concise explanation of Machine Learning concepts.\n",
      "* Inclusion of different learning paradigms.\n",
      "* Comprehensive list of real-world applications.\n",
      "* Discussion of key concepts like algorithms, data sets, and ethical considerations.\n",
      "* Balanced tone that acknowledges both the potential and limitations of ML.\n",
      "\n",
      "**Suggestions for improvement:**\n",
      "\n",
      "* **Add a section on the future of ML:** Discuss potential future applications, challenges, and ethical considerations.\n",
      "* **Provide more specific examples:** Include concrete examples of how ML is used in each application mentioned.\n",
      "* **Visualize complex concepts:** Consider using diagrams or illustrations to explain algorithms, data flow, and model performance.\n",
      "* **Simplify explanations for non-technical audiences:** Use analogies or relatable metaphors to explain technical terms.\n",
      "* **Consider the impact of ML on society:** Discuss potential job displacement and social implications.\n",
      "\n",
      "**Additional recommendations:**\n",
      "\n",
      "* Briefly explain different types of ML algorithms (e.g., linear regression, logistic regression, decision trees, k-nearest neighbors).\n",
      "* Include a section on applications of ML in specific industries like healthcare, finance, and education.\n",
      "* Discuss the importance of data quality and feature engineering in ML model performance.\n"
     ]
    }
   ],
   "source": [
    "def refine_prompt(initial_prompt, topic, iterations=3):\n",
    "    \"\"\"Refine a prompt through multiple iterations.\n",
    "\n",
    "    Args:\n",
    "        initial_prompt (PromptTemplate): The starting prompt template.\n",
    "        topic (str): The topic to explain.\n",
    "        iterations (int): Number of refinement iterations.\n",
    "\n",
    "    Returns:\n",
    "        PromptTemplate: The final refined prompt template.\n",
    "    \"\"\"\n",
    "    current_prompt = initial_prompt\n",
    "    for i in range(iterations):\n",
    "        try:\n",
    "            response = generate_response(current_prompt.format(topic=topic))\n",
    "        except KeyError as e:\n",
    "            print(f\"Error in iteration {i+1}: Missing key {e}. Adjusting prompt...\")\n",
    "            # Remove the problematic placeholder\n",
    "            current_prompt.template = current_prompt.template.replace(f\"{{{e.args[0]}}}\", \"relevant example\")\n",
    "            response = generate_response(current_prompt.format(topic=topic))\n",
    "        \n",
    "        # Generate feedback and suggestions for improvement\n",
    "        feedback_prompt = f\"Analyze the following explanation of {topic} and suggest improvements to the prompt that generated it:\\n\\n{response}\"\n",
    "        feedback = generate_response(feedback_prompt)\n",
    "        \n",
    "        # Use the feedback to refine the prompt\n",
    "        refine_prompt = f\"Based on this feedback: '{feedback}', improve the following prompt template. Ensure to only use the variable {{topic}} in your template:\\n\\n{current_prompt.template}\"\n",
    "        refined_template = generate_response(refine_prompt)\n",
    "        \n",
    "        current_prompt = PromptTemplate(\n",
    "            input_variables=[\"topic\"],\n",
    "            template=refined_template\n",
    "        )\n",
    "        \n",
    "        print(f\"Iteration {i+1} prompt: {current_prompt.template}\")\n",
    "    \n",
    "    return current_prompt\n",
    "\n",
    "# Perform A/B test\n",
    "topic = \"machine learning\"\n",
    "response_a = generate_response(prompt_a.format(topic=topic))\n",
    "response_b = generate_response(prompt_b.format(topic=topic))\n",
    "\n",
    "criteria = [\"clarity\", \"informativeness\", \"engagement\"]\n",
    "score_a = evaluate_response(response_a, criteria)\n",
    "score_b = evaluate_response(response_b, criteria)\n",
    "\n",
    "print(f\"Prompt A score: {score_a:.2f}\")\n",
    "print(f\"Prompt B score: {score_b:.2f}\")\n",
    "print(f\"Winning prompt: {'A' if score_a > score_b else 'B'}\")\n",
    "\n",
    "# Start with the winning prompt from A/B testing\n",
    "initial_prompt = prompt_b if score_b > score_a else prompt_a\n",
    "refined_prompt = refine_prompt(initial_prompt, \"machine learning\")\n",
    "\n",
    "print(\"\\nFinal refined prompt:\")\n",
    "print(refined_prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing Original and Refined Prompts\n",
    "\n",
    "Let's compare the performance of the original and refined prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating response based on clarity...\n",
      "Evaluating response based on informativeness...\n",
      "Evaluating response based on engagement...\n",
      "Evaluating response based on clarity...\n",
      "Evaluating response based on informativeness...\n",
      "Evaluating response based on engagement...\n",
      "Original prompt score: 8.00\n",
      "Refined prompt score: 9.00\n",
      "Improvement: 1.00 points\n"
     ]
    }
   ],
   "source": [
    "original_response = generate_response(initial_prompt.format(topic=\"machine learning\"))\n",
    "refined_response = generate_response(refined_prompt.format(topic=\"machine learning\"))\n",
    "\n",
    "original_score = evaluate_response(original_response, criteria)\n",
    "refined_score = evaluate_response(refined_response, criteria)\n",
    "\n",
    "print(f\"Original prompt score: {original_score:.2f}\")\n",
    "print(f\"Refined prompt score: {refined_score:.2f}\")\n",
    "print(f\"Improvement: {(refined_score - original_score):.2f} points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_inv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
