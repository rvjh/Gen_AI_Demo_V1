{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Few-Shot Learning and In-Context Learning Tutorial\n",
    "\n",
    "Traditional machine learning often requires large datasets for training, which can be time-consuming and resource-intensive. Few-Shot Learning and In-Context Learning address this limitation by leveraging the power of large language models to perform tasks with just a handful of examples. This approach is particularly valuable in scenarios where labeled data is scarce or expensive to obtain.\n",
    "\n",
    "Key Components\n",
    "\n",
    "1. LangChain Library: A powerful tool that simplifies the process of working with large language models.\n",
    "2. PromptTemplate: A structured way to format inputs for the language model.\n",
    "3. LLMChain: Manages the interaction between the prompt and the language model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method Details\n",
    "\n",
    "1. Basic Few-Shot Learning\n",
    "Implementation of a sentiment classification task using few-shot learning.\n",
    "Demonstration of how to structure a prompt with examples for the model to learn from.\n",
    "Explanation of how the model generalizes from these examples to new inputs.\n",
    "2. Advanced Few-Shot Techniques\n",
    "Exploration of multi-task learning for sentiment analysis and language detection.\n",
    "Discussion on how to design prompts that enable a single model to perform multiple related tasks.\n",
    "Insights into the benefits of this approach, such as improved efficiency and better generalization.\n",
    "3. In-Context Learning\n",
    "Demonstration of in-context learning for a custom task (e.g., text transformation).\n",
    "Explanation of how models can adapt to new tasks based solely on examples provided in the prompt.\n",
    "Discussion on the flexibility and limitations of this approach.\n",
    "4. Best Practices and Evaluation\n",
    "Guidelines for selecting effective examples for few-shot learning.\n",
    "Techniques for prompt engineering to optimize model performance.\n",
    "Implementation of an evaluation framework to assess model accuracy.\n",
    "Discussion on the importance of diverse test cases and appropriate metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x7f361393c460>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x7f361393d120>, model_name='gemma-7b-it', groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "groq_api_key = \"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\"\n",
    "\n",
    "llm = ChatGroq(\n",
    "     groq_api_key = groq_api_key,\n",
    "     model = \"gemma-7b-it\"\n",
    ")\n",
    "\n",
    "llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Few-Shot Learning\n",
    "\n",
    "We'll implement a basic few-shot learning scenario for sentiment classification.\n",
    "\n",
    "Sentiment Classification:\n",
    "\n",
    "Definition: Determining the emotional tone behind a series of words.\n",
    "Applications: Customer service, market research, social media analysis.\n",
    "\n",
    "Few-Shot Learning Approach:\n",
    "\n",
    "Provide a small set of labeled examples (3 in this case).\n",
    "Structure the prompt to clearly present examples and the new input.\n",
    "Leverage the pre-trained knowledge of the language model.\n",
    "\n",
    "Key Components:\n",
    "\n",
    "PromptTemplate: Structures the input for the model.\n",
    "LLMChain: Manages the interaction between the prompt and the language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: I can't believe how great this new restaurant is!\n",
      "Predicted Sentiment: Positive**\n",
      "\n",
      "The statement expresses strong delight and amazement towards the new restaurant.\n"
     ]
    }
   ],
   "source": [
    "def few_shot_sentiment_classification(input_text):\n",
    "    few_shot_prompt = PromptTemplate(\n",
    "        input_variables=[\"input_text\"],\n",
    "        template=\"\"\"\n",
    "        Classify the sentiment as Positive, Negative, or Neutral.\n",
    "        \n",
    "        Examples:\n",
    "        Text: I love this product! It's amazing.\n",
    "        Sentiment: Positive\n",
    "        \n",
    "        Text: This movie was terrible. I hated it.\n",
    "        Sentiment: Negative\n",
    "        \n",
    "        Text: The weather today is okay.\n",
    "        Sentiment: Neutral\n",
    "        \n",
    "        Now, classify the following:\n",
    "        Text: {input_text}\n",
    "        Sentiment:\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    chain = few_shot_prompt | llm\n",
    "    result = chain.invoke(input_text).content\n",
    "\n",
    "    # Clean up the result\n",
    "    result = result.strip()\n",
    "    # Extract only the sentiment label\n",
    "    if ':' in result:\n",
    "        result = result.split(':')[1].strip()\n",
    "    \n",
    "    return result  # This will now return just \"Positive\", \"Negative\", or \"Neutral\"\n",
    "\n",
    "test_text = \"I can't believe how great this new restaurant is!\"\n",
    "result = few_shot_sentiment_classification(test_text)\n",
    "print(f\"Input: {test_text}\")\n",
    "print(f\"Predicted Sentiment: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advanced Few-Shot Techniques\n",
    "\n",
    "We'll now explore multi-task learning for sentiment analysis and language detection.\n",
    "\n",
    "Multi-task Learning:\n",
    "\n",
    "Definition: Training a model to perform multiple related tasks simultaneously.\n",
    "Benefits: Improved efficiency, better generalization, reduced overfitting.\n",
    "Implementation:\n",
    "\n",
    "Design a prompt template that includes examples for multiple tasks.\n",
    "Use task-specific instructions to guide the model's behavior.\n",
    "Demonstrate how the same model can switch between tasks based on input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Result:** Positive\n",
      "**Result:** German\n"
     ]
    }
   ],
   "source": [
    "def multi_task_few_shot(input_text, task):\n",
    "    few_shot_prompt = PromptTemplate(\n",
    "        input_variables=[\"input_text\", \"task\"],\n",
    "        template=\"\"\"\n",
    "        Perform the specified task on the given text.\n",
    "        \n",
    "        Examples:\n",
    "        Text: I love this product! It's amazing.\n",
    "        Task: sentiment\n",
    "        Result: Positive\n",
    "        \n",
    "        Text: Bonjour, comment allez-vous?\n",
    "        Task: language\n",
    "        Result: French\n",
    "        \n",
    "        Now, perform the following task:\n",
    "        Text: {input_text}\n",
    "        Task: {task}\n",
    "        Result:\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    chain = few_shot_prompt | llm\n",
    "    return chain.invoke({\"input_text\": input_text, \"task\": task}).content\n",
    "\n",
    "print(multi_task_few_shot(\"I can't believe how great this is!\", \"sentiment\"))\n",
    "print(multi_task_few_shot(\"Guten Tag, wie geht es Ihnen?\", \"language\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In-Context Learning\n",
    "\n",
    "In-Context Learning allows models to adapt to new tasks based on examples provided in the prompt.\n",
    "\n",
    "Key Aspects:\n",
    "\n",
    "No fine-tuning required: The model learns from examples in the prompt.\n",
    "\n",
    "Flexibility: Can be applied to a wide range of tasks.\n",
    "\n",
    "Prompt engineering: Careful design of prompts is crucial for performance.\n",
    "\n",
    "Example Implementation: We'll demonstrate in-context learning for a custom task (converting text to pig latin)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: python\n",
      "Output: pythononay\n"
     ]
    }
   ],
   "source": [
    "def in_context_learning(task_description, examples, input_text):\n",
    "    example_text = \"\".join([f\"Input: {e['input']}\\nOutput: {e['output']}\\n\\n\" for e in examples])\n",
    "    \n",
    "    in_context_prompt = PromptTemplate(\n",
    "        input_variables=[\"task_description\", \"examples\", \"input_text\"],\n",
    "        template=\"\"\"\n",
    "        Task: {task_description}\n",
    "        \n",
    "        Examples:\n",
    "        {examples}\n",
    "        \n",
    "        Now, perform the task on the following input:\n",
    "        Input: {input_text}\n",
    "        Output:\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    chain = in_context_prompt | llm\n",
    "    return chain.invoke({\"task_description\": task_description, \"examples\": example_text, \"input_text\": input_text}).content\n",
    "\n",
    "task_desc = \"Convert the given text to pig latin.\"\n",
    "examples = [\n",
    "    {\"input\": \"hello\", \"output\": \"ellohay\"},\n",
    "    {\"input\": \"apple\", \"output\": \"appleay\"}\n",
    "]\n",
    "test_input = \"python\"\n",
    "\n",
    "result = in_context_learning(task_desc, examples, test_input)\n",
    "print(f\"Input: {test_input}\")\n",
    "print(f\"Output: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Practices and Evaluation\n",
    "\n",
    "To maximize the effectiveness of few-shot and in-context learning:\n",
    "\n",
    "Example Selection:\n",
    "\n",
    "1. Diversity: Cover different aspects of the task.\n",
    "2. Clarity: Use unambiguous examples.\n",
    "3. Relevance: Choose examples similar to expected inputs.\n",
    "4. Balance: Ensure equal representation of classes/categories.\n",
    "5. Edge cases: Include examples of unusual or difficult cases.\n",
    "\n",
    "Prompt Engineering:\n",
    "\n",
    "1. Clear instructions: Specify the task explicitly.\n",
    "2. Consistent format: Maintain a uniform structure for examples and inputs.\n",
    "3. Conciseness: Avoid unnecessary information that may confuse the model.\n",
    "\n",
    "Evaluation:\n",
    "\n",
    "1. Create a diverse test set.\n",
    "2. Compare model predictions to true labels.\n",
    "3. Use appropriate metrics (e.g., accuracy, F1 score) based on the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: This product exceeded my expectations!\n",
      "Predicted: ** This product exceeded my expectations!\n",
      "\n",
      "**Sentiment\n",
      "Actual: Positive\n",
      "Correct: False\n",
      "\n",
      "Input: I'm utterly disappointed with the service.\n",
      "Predicted: Negative**\n",
      "\n",
      "The sentence expresses a strong sense of disappointment and dissatisfaction with the service.\n",
      "Actual: Negative\n",
      "Correct: False\n",
      "\n",
      "Input: The temperature today is 72 degrees.\n",
      "Predicted: Neutral.\n",
      "\n",
      "The text simply states a factual piece of information about the temperature and does not express any subjective opinion or emotion.\n",
      "Actual: Neutral\n",
      "Correct: False\n",
      "\n",
      "Model Accuracy: 0.00\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model_func, test_cases):\n",
    "    '''\n",
    "    Evaluate the model on a set of test cases.\n",
    "\n",
    "    Args:\n",
    "    model_func: The function that makes predictions.\n",
    "    test_cases: A list of dictionaries, where each dictionary contains an \"input\" text and a \"label\" for the input.\n",
    "\n",
    "    Returns:\n",
    "    The accuracy of the model on the test cases. \n",
    "    '''\n",
    "    correct = 0\n",
    "    total = len(test_cases)\n",
    "    \n",
    "    for case in test_cases:\n",
    "        input_text = case['input']\n",
    "        true_label = case['label']\n",
    "        prediction = model_func(input_text).strip()\n",
    "        \n",
    "        is_correct = prediction.lower() == true_label.lower()\n",
    "        correct += int(is_correct)\n",
    "        \n",
    "        print(f\"Input: {input_text}\")\n",
    "        print(f\"Predicted: {prediction}\")\n",
    "        print(f\"Actual: {true_label}\")\n",
    "        print(f\"Correct: {is_correct}\\n\")\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "test_cases = [\n",
    "    {\"input\": \"This product exceeded my expectations!\", \"label\": \"Positive\"},\n",
    "    {\"input\": \"I'm utterly disappointed with the service.\", \"label\": \"Negative\"},\n",
    "    {\"input\": \"The temperature today is 72 degrees.\", \"label\": \"Neutral\"}\n",
    "]\n",
    "\n",
    "accuracy = evaluate_model(few_shot_sentiment_classification, test_cases)\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_inv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
