{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conversation summarization pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x7fc6278611e0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x7fc627841ae0>, model_name='gemma-7b-it', groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# Initialize the Groq API with your key\n",
    "groq_api_key = \"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\"\n",
    "llm = ChatGroq(\n",
    "    groq_api_key=groq_api_key,\n",
    "    model=\"gemma-7b-it\"\n",
    ")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_conversation_pipeline(conversation, summary_type=\"brief\"):\n",
    "    \"\"\"\n",
    "    Summarize a conversation using an LLM.\n",
    "    \n",
    "    :param conversation: A list of messages in the conversation (e.g., [{\"speaker\": \"User\", \"text\": \"Hello!\"}, ...]).\n",
    "    :param summary_type: Type of summary (\"brief\", \"detailed\", etc.).\n",
    "    :return: Summarized conversation text.\n",
    "    \"\"\"\n",
    "    # Format the conversation into a readable format\n",
    "    formatted_conversation = \"\\n\".join([f\"{msg['speaker']}: {msg['text']}\" for msg in conversation])\n",
    "\n",
    "    # Define the summarization prompt\n",
    "    template = \"\"\"\n",
    "    You are an AI assistant specialized in summarizing conversations. Your task is to create a {summary_type} summary of the following conversation.\n",
    "\n",
    "    Conversation:\n",
    "    {conversation}\n",
    "\n",
    "    Summary:\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create the prompt\n",
    "    prompt = PromptTemplate(template=template, input_variables=[\"summary_type\", \"conversation\"])\n",
    "    \n",
    "    # Create an LLM chain\n",
    "    llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "    \n",
    "    # Run the chain\n",
    "    response = llm_chain.run({\"summary_type\": summary_type, \"conversation\": formatted_conversation})\n",
    "    \n",
    "    # Debugging: Print raw response\n",
    "    print(f\"Raw Response: {response}\")\n",
    "    \n",
    "    # Clean and return the summary\n",
    "    try:\n",
    "        summary = response.strip()\n",
    "        return summary\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing response: {e}\")\n",
    "        return \"Error generating summary.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example conversation dataset\n",
    "conversation = [\n",
    "    {\"speaker\": \"User\", \"text\": \"Hi, can you help me with my order?\"},\n",
    "    {\"speaker\": \"Agent\", \"text\": \"Of course! Could you provide your order number?\"},\n",
    "    {\"speaker\": \"User\", \"text\": \"Sure, it's 12345.\"},\n",
    "    {\"speaker\": \"Agent\", \"text\": \"Thank you! I see your order is scheduled for delivery tomorrow.\"},\n",
    "    {\"speaker\": \"User\", \"text\": \"Great! Thanks for the update.\"},\n",
    "    {\"speaker\": \"Agent\", \"text\": \"You're welcome. Have a great day!\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2117580/3059707391.py:26: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
      "/tmp/ipykernel_2117580/3059707391.py:29: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
      "  response = llm_chain.run({\"summary_type\": summary_type, \"conversation\": formatted_conversation})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Response: **Summary:**\n",
      "\n",
      "A customer inquired about their order status and provided the order number (12345). The agent confirmed the order was scheduled for delivery the next day.\n",
      "Conversation Summary:\n",
      "**Summary:**\n",
      "\n",
      "A customer inquired about their order status and provided the order number (12345). The agent confirmed the order was scheduled for delivery the next day.\n"
     ]
    }
   ],
   "source": [
    "# Run the summarization pipeline\n",
    "summary = summarize_conversation_pipeline(conversation, summary_type=\"brief\")\n",
    "print(\"Conversation Summary:\")\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_inv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
